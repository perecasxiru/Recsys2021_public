{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74cc047b",
   "metadata": {},
   "source": [
    "# Author Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7487e0",
   "metadata": {},
   "source": [
    "This notebook computes popularity for the author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6b208a-95a0-4d6c-b60a-c5cfe6b195ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:36601</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>24</li>\n",
       "  <li><b>Memory: </b>125.60 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:36601' processes=6 threads=24, memory=125.60 GiB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d1ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eef682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92280ff7",
   "metadata": {},
   "source": [
    "## Author popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b786381-c9fe-4773-af55-7ad9c8e9926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge = pd.read_csv('/data/recsys/auth_pop_tweet/auth_merge.csv')\n",
    "# df_none = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa81ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4988ec5a553a42cabc4a84cc81b6d458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUTHOR POPULARITY\n",
    "\n",
    "df_merge=None\n",
    "df_none=True\n",
    "column_type = {\n",
    "    'bert': str, 'hashtags': str, 'tweet_id': str, 'media': str, 'links': str, 'domains': str, 'type': str, 'language': str, 'timestamp': np.uint32,\n",
    "    'AUTH_user_id':str,'AUTH_follower_count':np.uint32,'AUTH_following_count':np.uint32,'AUTH_verified':bool,'AUTH_account_creation':np.uint32,\n",
    "    'READ_user_id': str,'READ_follower_count':np.uint32,'READ_following_count':np.uint32,'READ_verified':bool,'READ_account_creation':np.uint32,\n",
    "    'auth_follows_read': bool,\n",
    "    'reply_timestamp':np.float32,'retweet_timestamp':np.float32,'quote_timestamp':np.float32,'like_timestamp':np.float32\n",
    "}\n",
    "\n",
    "for idx in trange(0, 504):\n",
    "    \n",
    "    # Read a csv\n",
    "    df = pd.read_csv(f'/data/recsys/sorted/part-{idx:05d}.csv', \n",
    "                     usecols=['AUTH_user_id', 'reply_timestamp','retweet_timestamp','quote_timestamp','like_timestamp', 'tweet_id'], \n",
    "                     dtype=column_type)\n",
    "    \n",
    "    # Transform timestamp to integer (1 if timestamp present, 0 otherwise)\n",
    "    df['reply_timestamp'] = (df['reply_timestamp']>0).astype(int)\n",
    "    df['retweet_timestamp'] = (df['retweet_timestamp']>0).astype(int)\n",
    "    df['quote_timestamp'] = (df['quote_timestamp']>0).astype(int)\n",
    "    df['like_timestamp'] = (df['like_timestamp']>0).astype(int)\n",
    "            \n",
    "    # Cumulated sum (interactions are sorted by timestamp)\n",
    "    df[['reply', 'retweet', 'quote', 'like']] = df.groupby('AUTH_user_id').cumsum()\n",
    "    \n",
    "    # Cumulated count to know how many repetitions we have\n",
    "    df['AUTH_count_user_id'] = df.groupby('AUTH_user_id').cumcount()\n",
    "    \n",
    "    # Cumulated count to know how many repetitions we have\n",
    "    df['tweet_id_count'] = df.groupby('tweet_id').cumcount()\n",
    "    \n",
    "     # Cumulated count to know how many repetitions we have\n",
    "    df['like_id_count'] = df.groupby(['AUTH_user_id', 'tweet_id'])['like_timestamp'].cumsum() - df['like_timestamp']\n",
    "    df['retweet_id_count'] = df.groupby(['AUTH_user_id', 'tweet_id'])['retweet_timestamp'].cumsum() - df['retweet_timestamp']\n",
    "    df['quote_id_count'] = df.groupby(['AUTH_user_id', 'tweet_id'])['quote_timestamp'].cumsum() - df['quote_timestamp']\n",
    "    df['reply_id_count'] = df.groupby(['AUTH_user_id', 'tweet_id'])['reply_timestamp'].cumsum() - df['reply_timestamp']\n",
    "    \n",
    "    df = df.drop(columns=['tweet_id'])\n",
    "    \n",
    "    if not df_none:\n",
    "        df = df.set_index('AUTH_user_id')\n",
    "       \n",
    "        # FIXED: It is important this line to have the reindex at the end, otherwise data will loose its initial order.\n",
    "        # Notebook 04.1 fixes that but here is already corrected\n",
    "        df = df.add(df_merge.loc[df_merge.index.intersection(df.index)].reindex(df.index), fill_value=0)\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    df['a_count'] = df['AUTH_count_user_id'] - df['tweet_id_count']\n",
    "    \n",
    "    # Compute cumulated mean\n",
    "    df['avg_reply'] = ((df['reply'] - df['reply_id_count'] - df['reply_timestamp']) / df['a_count']).fillna(0)\n",
    "    df['avg_retweet'] = ((df['retweet'] - df['retweet_id_count'] - df['retweet_timestamp']) / df['a_count']).fillna(0)\n",
    "    df['avg_quote'] = ((df['quote'] - df['quote_id_count'] - df['quote_timestamp']) / df['a_count']).fillna(0)\n",
    "    df['avg_like'] = ((df['like'] - df['like_id_count'] - df['like_timestamp']) / df['a_count']).fillna(0) \n",
    "\n",
    "    # Get sum per user so we know the last value for the next parts\n",
    "    # Rename columns so values will be added to the cumulative ones\n",
    "    df_tmp = df.loc[:, ['AUTH_user_id', 'reply_timestamp','retweet_timestamp','quote_timestamp','like_timestamp']].groupby('AUTH_user_id').sum()    \n",
    "    df_tmp = df_tmp.rename(columns={'reply_timestamp': 'reply','retweet_timestamp':'retweet',\n",
    "                                        'quote_timestamp':'quote','like_timestamp':'like'})\n",
    "    \n",
    "    # Get the total count per user so we know the appearances of this user\n",
    "    df_tmp[['AUTH_count_user_id']] = df.groupby('AUTH_user_id').count().AUTH_count_user_id    \n",
    "    \n",
    "    if df_none:\n",
    "        df_merge = df_tmp\n",
    "    else:\n",
    "        df_merge = df_merge.add(df_tmp, fill_value=0)\n",
    "        \n",
    "    df_none = False\n",
    "    \n",
    "    df[['avg_reply', 'avg_retweet', 'avg_quote', 'avg_like', 'AUTH_count_user_id', 'a_count']].to_csv(f'/data/recsys/auth_pop_tweet/part-{idx:05d}.csv', index=False)\n",
    "    del df_tmp\n",
    "    \n",
    "    if idx==336:\n",
    "        df_merge.to_csv('/data/recsys/auth_pop_tweet/auth_pop2w.csv')\n",
    "        \n",
    "    if (idx%50 == 0) and (idx > 0):\n",
    "        df_merge.to_csv('/data/recsys/auth_pop_tweet/auth_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv('/data/recsys/auth_pop_tweet/auth_merge.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
