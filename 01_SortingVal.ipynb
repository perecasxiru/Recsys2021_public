{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7bf0845",
   "metadata": {},
   "source": [
    "# Sorting Validation data\n",
    "\n",
    "This notebook sorts the data by timestamp.\n",
    "\n",
    "Data is expected to be located in `/data/recsys/part-XXXXX` and sorted data is going to be located in `/data/recsys/sorted/part-XXXXX.csv` where each file contains all the interactions of an hour.\n",
    "\n",
    "+ Min timestamp train: 1612396800 (04 February 2021 0:00:00)\n",
    "+ Min timestamp val: 1614211200 (25 February 2021 0:00:00)\n",
    "+ Max timestamp val: 1614815999 (03 March 2021 23:59:59) \n",
    "\n",
    "To convert from partID to hour do the following operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1dc4437-bb86-459a-9997-34073780fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e9502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_to_timestamp(partID):\n",
    "    import pandas as pd\n",
    "    min_h = pd.to_datetime(partID * 3600 + 1612396800, unit='s')\n",
    "    max_h = pd.to_datetime((partID + 1) * 3600 + 1612396800 - 1, unit='s')\n",
    "\n",
    "    print(f'Part {partID:03d} from time {min_h} to {max_h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96beb5",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cecfd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 000 from time 2021-02-04 00:00:00 to 2021-02-04 00:59:59\n",
      "Part 100 from time 2021-02-08 04:00:00 to 2021-02-08 04:59:59\n",
      "Part 503 from time 2021-02-24 23:00:00 to 2021-02-24 23:59:59\n",
      "Part 671 from time 2021-03-03 23:00:00 to 2021-03-03 23:59:59\n"
     ]
    }
   ],
   "source": [
    "part_to_timestamp(partID=0)\n",
    "part_to_timestamp(partID=100)\n",
    "part_to_timestamp(partID=503)\n",
    "part_to_timestamp(partID=671)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1cd868",
   "metadata": {},
   "source": [
    "## Read and sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f0f583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34515</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8788/status' target='_blank'>http://127.0.0.1:8788/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>24</li>\n",
       "  <li><b>Memory: </b>125.60 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:34515' processes=6 threads=24, memory=125.60 GiB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.dataframe as dd\n",
    "\n",
    "cluster = LocalCluster(dashboard_address=':8788')\n",
    "# cluster.scale(3)\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58cc23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_type={\n",
    "              'bert': str,'hashtags':str,'tweet_id':str,'media':str,'links':str,'domains':str,'type':str,'language':str,'timestamp':np.uint32,\n",
    "              'AUTH_user_id':str,'AUTH_follower_count':np.uint32,'AUTH_following_count':np.uint32,'AUTH_verified':bool,'AUTH_account_creation':np.uint32,\n",
    "              'READ_user_id':str,'READ_follower_count':np.uint32,'READ_following_count':np.uint32,'READ_verified':bool,'READ_account_creation':np.uint32,\n",
    "              'auth_follows_read':bool,\n",
    "              'reply_timestamp':'Int32','retweet_timestamp':'Int32','quote_timestamp':'Int32','like_timestamp':'Int32'\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7647a5ae",
   "metadata": {},
   "source": [
    "First, we separate the data by hour. Since **1612396800** is the minimum timestamp we can do:\n",
    "$$\\text{part} = \\left[\\dfrac{\\text{timestamp} - 1612396800}{3600}\\right], \\ \\ \\text{with} \\ \\ [] \\ \\ \\text{the Floor function}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5022ffa-6f9b-4b16-80b1-05f7cab39573",
   "metadata": {},
   "source": [
    "Read validation file and split by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a8f4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_csv('/data/recsys/valid/part-00000.1', names=list(column_type.keys()), header=None, sep='\\x01', dtype=column_type)\n",
    "df['part'] = df.apply(lambda row: (row.timestamp - 1612396800) // 3600, axis=1, meta=(None, 'uint16'))\n",
    "df.groupby('part').apply(lambda group: group.drop(columns=['part']).to_csv(f'/data/recsys/sorted/part-{group.name:05d}.csv',index=False), meta=df._meta).size.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054b876",
   "metadata": {},
   "source": [
    "Then, we can sort files individually,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f0034ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trange(504, 672):\n",
    "    df = pd.read_csv(f'/data/recsys/sorted/part-{i:05d}.csv')\n",
    "    df = df.sort_values('timestamp')\n",
    "    df.to_csv(f'/data/recsys/sorted/part-{i:05d}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35567f8",
   "metadata": {},
   "source": [
    "### Move\n",
    "\n",
    "Move files from `/data/recsys/valid` folder into `/data/recsys/RecsysDocker/test_4` folder to replicate the twitter docker execution. <br>\n",
    "Create the `reals_4.csv` to simulate the leaderboard score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721dd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /data/recsys/test_csv_w4\n",
    "# !mkdir /data/recsys/RecsysDocker/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7fa3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "_from, _to = 504, 504+7*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa8386be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in trange(_from, _to, leave=False):\n",
    "    f = f\"{i:05d}\"\n",
    "    !cp /data/recsys/sorted/part-{f}.csv /data/recsys/test_csv_w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f39120fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import trange\n",
    "reals = None\n",
    "for i in trange(_from, _to, leave=False):\n",
    "    df = pd.read_csv(f'/data/recsys/test_csv_w4/part-{i:05d}.csv')\n",
    "    if reals is None:\n",
    "        reals = df.iloc[:,-4:]\n",
    "    else:\n",
    "        reals = pd.concat([reals, df.iloc[:,-4:]])\n",
    "    df = df.iloc[:,:-4] \n",
    "    newi = i-_from\n",
    "    df.to_csv(f'/data/recsys/RecsysDocker/test_4/part-{newi:05d}', sep='\\x01', header=False, index=False)\n",
    "reals.notna().astype(int).to_csv(f'/data/recsys/RecsysDocker/reals_4.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b5bcea-9541-4a17-a944-c189c2240701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /data/recsys/test_csv_w4/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
