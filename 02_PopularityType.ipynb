{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74cc047b",
   "metadata": {},
   "source": [
    "# Popularity Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7487e0",
   "metadata": {},
   "source": [
    "This notebook computes popularity feature for both reader and author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d1ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eef682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd593e94",
   "metadata": {},
   "source": [
    "## Reader popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27a4887-2c00-46f0-840c-4125f16c6a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_type = {\n",
    "    'bert': str, 'hashtags': str, 'tweet_id': str, 'media': str, 'links': str, 'domains': str, 'type': str, 'language': str, 'timestamp': np.uint32,\n",
    "    'AUTH_user_id':str,'AUTH_follower_count':np.uint32,'AUTH_following_count':np.uint32,'AUTH_verified':bool,'AUTH_account_creation':np.uint32,\n",
    "    'READ_user_id': str,'READ_follower_count':np.uint32,'READ_following_count':np.uint32,'READ_verified':bool,'READ_account_creation':np.uint32,\n",
    "    'auth_follows_read': bool,\n",
    "    'reply_timestamp':np.float32,'retweet_timestamp':np.float32,'quote_timestamp':np.float32,'like_timestamp':np.float32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805cbff6-d107-4958-9c8f-343a3da7c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid, userfo = 'AUTH', 'auth' #'AUTH', 'auth'  #'READ', 'read'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f0ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6a033f4f7640c0b2a28a4d131a2468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_merge=None\n",
    "df_none=True\n",
    "for idx in trange(0, 504):\n",
    "    \n",
    "    # Read a csv\n",
    "    df = pd.read_csv(f'/data/recsys/sorted/part-{idx:05d}.csv', \n",
    "                     usecols=[userid + '_user_id','type','reply_timestamp','retweet_timestamp','quote_timestamp','like_timestamp'], \n",
    "                     dtype=column_type)\n",
    "    \n",
    "    # Transform timestamp to integer (1 if timestamp present, 0 otherwise)\n",
    "    df['rep_T'] = ((df['reply_timestamp']>0) & (df['type']=='TopLevel')).astype(np.uint16)\n",
    "    df['ret_T'] = ((df['retweet_timestamp']>0) & (df['type']=='TopLevel')) .astype(np.uint16)\n",
    "    df['quo_T'] = ((df['quote_timestamp']>0) & (df['type']=='TopLevel')).astype(np.uint16)\n",
    "    df['lik_T'] = ((df['like_timestamp']>0) & (df['type']=='TopLevel')).astype(np.uint16)\n",
    "    \n",
    "    df['rep_R'] = ((df['reply_timestamp']>0) & (df['type']=='Retweet')).astype(np.uint16)\n",
    "    df['ret_R'] = ((df['retweet_timestamp']>0) & (df['type']=='Retweet')) .astype(np.uint16)\n",
    "    df['quo_R'] = ((df['quote_timestamp']>0) & (df['type']=='Retweet')).astype(np.uint16)\n",
    "    df['lik_R'] = ((df['like_timestamp']>0) & (df['type']=='Retweet')).astype(np.uint16)\n",
    "    \n",
    "    df['rep_Q'] = ((df['reply_timestamp']>0) & (df['type']=='Quote')).astype(np.uint16)\n",
    "    df['ret_Q'] = ((df['retweet_timestamp']>0) & (df['type']=='Quote')) .astype(np.uint16)\n",
    "    df['quo_Q'] = ((df['quote_timestamp']>0) & (df['type']=='Quote')).astype(np.uint16)\n",
    "    df['lik_Q'] = ((df['like_timestamp']>0) & (df['type']=='Quote')).astype(np.uint16)\n",
    "    \n",
    "    # One hot for the type\n",
    "    df['is_T'] = (df['type']=='TopLevel').astype(np.uint16)\n",
    "    df['is_R'] = (df['type']=='Retweet').astype(np.uint16)\n",
    "    df['is_Q'] = (df['type']=='Quote').astype(np.uint16)\n",
    "        \n",
    "    df = df.drop(columns=['type','reply_timestamp','retweet_timestamp','quote_timestamp','like_timestamp'])\n",
    "    \n",
    "    # Cumulated sum (interactions are sorted by timestamp)\n",
    "    df[['rep_cT', 'ret_cT', 'quo_cT', 'lik_cT', 'rep_cR', 'ret_cR', 'quo_cR', 'lik_cR', 'rep_cQ', 'ret_cQ', 'quo_cQ', 'lik_cQ', 'is_cT', 'is_cR', 'is_cQ']] = df.groupby(userid + '_user_id').cumsum().astype(np.uint16)\n",
    "    \n",
    "    if not df_none:\n",
    "        df = df.set_index(userid + '_user_id')\n",
    "        \n",
    "        # FIXED: It is important this line to have the reindex at the end, otherwise data will loose its initial order.\n",
    "        # Notebook 04.1 fixes that but here is already corrected\n",
    "        df = df.add(df_merge.loc[df_merge.index.intersection(df.index)].reindex(df.index), fill_value=0)\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    df['is_aT'] = df['is_cT'] - df['is_T']\n",
    "    df['is_aR'] = df['is_cR'] - df['is_R']\n",
    "    df['is_aQ'] = df['is_cQ'] - df['is_Q']\n",
    "    \n",
    "    # Compute cumulated mean\n",
    "    df['rep_aT'] = ((df['rep_cT'] - df['rep_T'])/df['is_aT']).fillna(0).astype(np.float16)\n",
    "    df['ret_aT'] = ((df['ret_cT'] - df['ret_T'])/df['is_aT']).fillna(0).astype(np.float16)\n",
    "    df['quo_aT'] = ((df['quo_cT'] - df['quo_T'])/df['is_aT']).fillna(0).astype(np.float16)\n",
    "    df['lik_aT'] = ((df['lik_cT'] - df['lik_T'])/df['is_aT']).fillna(0).astype(np.float16) \n",
    "    \n",
    "    df['rep_aR'] = ((df['rep_cR'] - df['rep_R'])/df['is_aR']).fillna(0).astype(np.float16)\n",
    "    df['ret_aR'] = ((df['ret_cR'] - df['ret_R'])/df['is_aR']).fillna(0).astype(np.float16)\n",
    "    df['quo_aR'] = ((df['quo_cR'] - df['quo_R'])/df['is_aR']).fillna(0).astype(np.float16)\n",
    "    df['lik_aR'] = ((df['lik_cR'] - df['lik_R'])/df['is_aR']).fillna(0).astype(np.float16) \n",
    "    \n",
    "    df['rep_aQ'] = ((df['rep_cQ'] - df['rep_Q'])/df['is_aQ']).fillna(0).astype(np.float16)\n",
    "    df['ret_aQ'] = ((df['ret_cQ'] - df['ret_Q'])/df['is_aQ']).fillna(0).astype(np.float16)\n",
    "    df['quo_aQ'] = ((df['quo_cQ'] - df['quo_Q'])/df['is_aQ']).fillna(0).astype(np.float16)\n",
    "    df['lik_aQ'] = ((df['lik_cQ'] - df['lik_Q'])/df['is_aQ']).fillna(0).astype(np.float16) \n",
    "    \n",
    "    \n",
    "        \n",
    "    # Get sum per user so we know the last value for the next parts\n",
    "    # Rename columns so values will be added to the cumulative ones\n",
    "    df_tmp = df.loc[:,[userid + '_user_id', 'rep_T', 'ret_T', 'quo_T', 'lik_T', 'rep_R', 'ret_R', 'quo_R', 'lik_R', 'rep_Q', 'ret_Q', 'quo_Q', 'lik_Q', 'is_T', 'is_R', 'is_Q']].groupby(userid + '_user_id').sum()    \n",
    "    df_tmp = df_tmp.rename(columns={'rep_T': 'rep_cT','ret_T':'ret_cT','quo_T':'quo_cT','lik_T':'lik_cT',\n",
    "                                    'rep_R': 'rep_cR','ret_R':'ret_cR','quo_R':'quo_cR','lik_R':'lik_cR',\n",
    "                                    'rep_Q': 'rep_cQ','ret_Q':'ret_cQ','quo_Q':'quo_cQ','lik_Q':'lik_cQ',\n",
    "                                    'is_T': 'is_cT', 'is_R': 'is_cR', 'is_Q':'is_cQ'})\n",
    "    \n",
    "    # Get the total count per user so we know the appearances of this user\n",
    "#     df_tmp[userid + '_count_user_id'] = df.groupby(userid + '_user_id').count()[userid + '_count_user_id']\n",
    "        \n",
    "    if df_none:\n",
    "        df_merge = df_tmp\n",
    "    else:\n",
    "        df_merge = df_merge.add(df_tmp, fill_value=0)\n",
    "        \n",
    "    df_none = False\n",
    "    \n",
    "    df[['rep_aT', 'ret_aT', 'quo_aT', 'lik_aT', 'rep_aR', 'ret_aR', 'quo_aR', 'lik_aR', 'rep_aQ', 'ret_aQ', 'quo_aQ', 'lik_aQ', 'is_aT', 'is_aR', 'is_aQ']].to_csv(f'/data/recsys/tef_{userfo}_tt/part-{idx:05d}.csv', index=False)\n",
    "    del df_tmp\n",
    "    \n",
    "    if idx==335:\n",
    "        df_merge.to_csv(f'/data/recsys/tef_{userfo}_tt/{userfo}_merge2w.csv')\n",
    "    \n",
    "    if (idx%50 == 0) and (idx > 0):\n",
    "        df_merge.to_csv(f'/data/recsys/tef_{userfo}_tt/{userfo}_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2994a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv(f'/data/recsys/tef_{userfo}_tt/{userfo}_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c155f20-7cb3-4507-9926-240accce11b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTH_user_id</th>\n",
       "      <th>rep_cT</th>\n",
       "      <th>ret_cT</th>\n",
       "      <th>quo_cT</th>\n",
       "      <th>lik_cT</th>\n",
       "      <th>rep_cR</th>\n",
       "      <th>ret_cR</th>\n",
       "      <th>quo_cR</th>\n",
       "      <th>lik_cR</th>\n",
       "      <th>rep_cQ</th>\n",
       "      <th>ret_cQ</th>\n",
       "      <th>quo_cQ</th>\n",
       "      <th>lik_cQ</th>\n",
       "      <th>is_cT</th>\n",
       "      <th>is_cR</th>\n",
       "      <th>is_cQ</th>\n",
       "      <th>rep_aT</th>\n",
       "      <th>ret_aT</th>\n",
       "      <th>quo_aT</th>\n",
       "      <th>lik_aT</th>\n",
       "      <th>rep_aR</th>\n",
       "      <th>ret_aR</th>\n",
       "      <th>quo_aR</th>\n",
       "      <th>lik_aR</th>\n",
       "      <th>rep_aQ</th>\n",
       "      <th>ret_aQ</th>\n",
       "      <th>quo_aQ</th>\n",
       "      <th>lik_aQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000003E526B400CDE80ED2A251E01F8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000897155185FFB03C2F675586F22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000013D8DEA682123394057F06845B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000020FE53C9B5EED183B7DE154E2FD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000300B559E34751BA6CB8F7ACE16B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       AUTH_user_id  rep_cT  ret_cT  quo_cT  lik_cT  rep_cR  \\\n",
       "0  0000003E526B400CDE80ED2A251E01F8     0.0     0.0     0.0     0.0     0.0   \n",
       "1  000000897155185FFB03C2F675586F22     0.0     0.0     0.0     0.0     0.0   \n",
       "2  0000013D8DEA682123394057F06845B1     0.0     0.0     0.0     0.0     0.0   \n",
       "3  0000020FE53C9B5EED183B7DE154E2FD     0.0     0.0     0.0     0.0     0.0   \n",
       "4  00000300B559E34751BA6CB8F7ACE16B     0.0     0.0     0.0     2.0     0.0   \n",
       "\n",
       "   ret_cR  quo_cR  lik_cR  rep_cQ  ret_cQ  quo_cQ  lik_cQ  is_cT  is_cR  \\\n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    1.0    0.0   \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0    2.0    9.0   \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0    0.0    1.0   \n",
       "3     0.0     0.0     1.0     0.0     0.0     0.0     0.0    0.0    2.0   \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0    3.0    0.0   \n",
       "\n",
       "   is_cQ  rep_aT  ret_aT  quo_aT    lik_aT  rep_aR  ret_aR  quo_aR  lik_aR  \\\n",
       "0    0.0     0.0     0.0     0.0  0.000000     NaN     NaN     NaN     NaN   \n",
       "1    0.0     0.0     0.0     0.0  0.000000     0.0     0.0     0.0     0.0   \n",
       "2    0.0     NaN     NaN     NaN       NaN     0.0     0.0     0.0     0.0   \n",
       "3    0.0     NaN     NaN     NaN       NaN     0.0     0.0     0.0     0.5   \n",
       "4    0.0     0.0     0.0     0.0  0.666667     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   rep_aQ  ret_aQ  quo_aQ  lik_aQ  \n",
       "0     NaN     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc42da54-afe7-4c92-9187-25ab0e6fdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/data/recsys/tef_{userfo}_tt/{userfo}_merge.csv')\n",
    "\n",
    "cols1 = ['rep_cT', 'ret_cT', 'quo_cT', 'lik_cT', 'rep_cR', 'ret_cR', 'quo_cR', 'lik_cR', 'rep_cQ', 'ret_cQ', 'quo_cQ', 'lik_cQ']\n",
    "cols2 = ['rep_aT', 'ret_aT', 'quo_aT', 'lik_aT', 'rep_aR', 'ret_aR', 'quo_aR', 'lik_aR', 'rep_aQ', 'ret_aQ', 'quo_aQ', 'lik_aQ']\n",
    "\n",
    "for c1, c2 in list(zip(cols1, cols2)):\n",
    "    df[c2] = df[c1]/df[f'is_c{c1[-1]}']\n",
    "    \n",
    "df.drop(columns = cols1).fillna(0).to_csv(f'/data/recsys/tef_{userfo}_tt/{userfo}_tt_merge_div.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cb4e8e-a766-4e5e-bce7-d1cf7e589232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'/data/recsys/tef_{userfo}_tt/{userfo}_merge2w.csv')\n",
    "\n",
    "cols1 = ['rep_cT', 'ret_cT', 'quo_cT', 'lik_cT', 'rep_cR', 'ret_cR', 'quo_cR', 'lik_cR', 'rep_cQ', 'ret_cQ', 'quo_cQ', 'lik_cQ']\n",
    "cols2 = ['rep_aT', 'ret_aT', 'quo_aT', 'lik_aT', 'rep_aR', 'ret_aR', 'quo_aR', 'lik_aR', 'rep_aQ', 'ret_aQ', 'quo_aQ', 'lik_aQ']\n",
    "\n",
    "for c1, c2 in list(zip(cols1, cols2)):\n",
    "    df[c2] = df[c1]/df[f'is_c{c1[-1]}']\n",
    "    \n",
    "df.drop(columns = cols1).fillna(0).to_csv(f'/data/recsys/tef_{userfo}_tt/{userfo}_tt_merge2w_div.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
